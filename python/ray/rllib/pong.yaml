tune-pong:
    env: PongDeterministic-v4
    alg: DQN
    max_trials: 40
    resources:
       cpu: 1
    stop:
        episode_reward_mean: 19
        timesteps_total: 1000000
        time_total_s: 20000
    parameters:
        lr:
            eval: random.choice([1e-5, 1e-4, 1e-3])
        schedule_max_timesteps:
            eval: random.choice([10, 10000, 100000, 1000000])
        sample_batch_size:
            eval: random.choice([1, 4, 8])
        train_batch_size:
            eval: random.choice([32, 128])
        target_network_update_freq:
            eval: random.choice([100, 1000])
        exploration_final_eps: .01
        exploration_fraction: .1
        gamma: 0.99
        learning_starts: 10000
        num_workers: 1
        prioritized_replay: True
