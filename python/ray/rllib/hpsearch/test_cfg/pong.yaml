tune-pong1:
    env: PongDeterministic-v4
    alg: DQN
    max_trials: 1
    resources:
       cpu: 1
       gpu: 0
    stop:
        episode_reward_mean: 19
    parameters:
        schedule_max_timesteps: 1000000
        sample_batch_size:
            eval: 4 ** (1 + (_i // 3))
        train_batch_size:
            eval: list([32, 128, 512])[_i % 3]
        target_network_update_freq: 500
        exploration_final_eps: .01
        exploration_fraction: .1
        gamma: 0.99
        learning_starts: 10000
        num_workers: 1
        prioritized_replay: True
        multi_gpu_optimize: True
